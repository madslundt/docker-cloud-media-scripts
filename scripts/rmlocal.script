#!/bin/bash
###############################################################################
# CONFIGURATION
###############################################################################
# shellcheck source=config

. "/usr/bin/variables"
##############################################################################

rm_time () {
	# Generate filelist and iterate through it...
	find "${local_decrypt_dir}" -type f -mtime +$REMOVE_LOCAL_FILES_AFTER_DAYS |
		while read -r n; do

			# Find the pathname relative to the root of your remote and store filename
			filename="$(echo "$n" | sed -e s@"${local_decrypt_dir}"@@)"
			destpath="$(dirname "$n" | sed -e s@"${local_decrypt_dir}"@@)"

			# Skip hidden or partial files.
			case "$n" in
				(*.partial~) continue ;;
				(*_HIDDEN~) continue ;;
				(*.QTFS) continue ;;
				(*.unionfs-fuse*) continue ;;
				(*.DS_STORE) continue ;;
			esac

			# If file is opened by another process, wait until it isn't.
			while [ "$(lsof "$n" >/dev/null 2>&1)" ] || \
				[ "$(lsof "${local_decrypt_dir}/${n}" >/dev/null 2>&1)" ] || \
				[ "$(lsof "${local_media_dir}/${n}" >/dev/null 2>&1)" ]; do
				echo "[ $(date $(printenv DATE_FORMAT)) ] File -> ${n} in use. Retrying in 10 seconds."
				sleep 10
			done

			# Move file to remote destination[s], retaining path
			echo "[ $(date $(printenv DATE_FORMAT)) ] Moving file -> ${n} to Google Drive."
			rclone move $rclone_options "$@" "$n" "$(printenv RCLONE_CLOUD_ENDPOINT)${destpath}" >/dev/null 2>&1
		done
}

rm_space () {
	maxSize=$(($REMOVE_LOCAL_FILES_WHEN_SPACE_EXCEEDS_GB * 1000 * 1000 * 1000))
	currentSize="$(du -sb "$local_decrypt_dir" | awk '{print $1}')"
	if [ "$maxSize" -gt "$currentSize" ]; then
			echo "Current size of $(($currentSize / 1000 / 1000 / 1000)) GB has not exceeded $REMOVE_LOCAL_FILES_WHEN_SPACE_EXCEEDS_GB GB"
			exit 02
	fi

	addedSpace=0
	freeup=$(($FREEUP_ATLEAST_GB * 1000 * 1000 * 1000))

	find "${local_decrypt_dir}" -type f -exec stat -c "%x %n" {} \; | sort | awk '{$1=$2=$3=""; print $0}' |
		while read -r n; do
			if [ "$addedSpace" -gt "$freeup" ]; then
					spaceInGb=$(($addedSpace / 1000 / 1000 / 1000))
					spaceLeft=$(($(du -sb "$local_decrypt_dir" | awk '{print $1}') / 1000 / 1000 / 1000))
					echo "[ $(date $(printenv DATE_FORMAT)) ] Removed ${spaceInGb} GB. Media in total ${spaceLeft} GB."
					break
			fi

			# Find the pathname relative to the rsoot of your remote and store filename
			filename="$(echo "$n" | sed -e s@"${local_decrypt_dir}"@@)"
			destpath="$(dirname "$n" | sed -e s@"${local_decrypt_dir}"@@)"

			# Skip hidden or partial files.
			case "$n" in
					(*.partial~) continue ;;
					(*_HIDDEN~) continue ;;
					(*.QTFS) continue ;;
					(*.fuse*) continue ;;
					(.DS_STORE) continue ;;
			esac

			# If file is opened by another process, wait until it isn't.
			while [ "$(lsof "$n" >/dev/null 2>&1)" ] || \
					[ "$(lsof "${local_decrypt_dir}/${n}" >/dev/null 2>&1)" ] || \
					[ "$(lsof "${local_media_dir}/${n}" >/dev/null 2>&1)" ]; do
					echo "[ $(date $(printenv DATE_FORMAT)) ] File -> ${n} in use. Retrying in 10 seconds."
					sleep 10
			done

			echo $n

			fileSize=$(du -sb "$n" | awk '{print $1}')
			addedSpace="$(($addedSpace + $fileSize))"

			fileSizeGb=$(($fileSize / 1000 / 1000 / 1000))

			# Move file to remote destination[s], retaining path
			echo "[ $(date $(printenv DATE_FORMAT)) ] Moving file -> ${n} to Google Drive. Freeing up ${fileSizeGb} GB"
			rclone move $rclone_options "$@" "$n" "$(printenv RCLONE_CLOUD_ENDPOINT)${destpath}" >/dev/null 2>&1
	done
}

# If script is already running; abort.
if pidof -o %PPID -x "$(basename "$0")"; then
	echo "[ $(date $(printenv DATE_FORMAT)) ] Upload already in progress. Aborting."
	exit 3
fi

check_rclone_cloud

if [ "$REMOVE_LOCAL_FILES_BASED_ON" = "space" ]; then
	rm_space
elif [ "$REMOVE_LOCAL_FILES_BASED_ON" = "time" ]; then
	rm_time
else
	echo "[ $(date $(printenv DATE_FORMAT)) ] no option to remove old files"
	exit 02
fi
